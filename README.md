![download](https://github.com/user-attachments/assets/5842e84e-004f-4afd-9373-af64e9575b78)
<h3 align="center">üöÄ One-stop solution for creating your digital avatar from chat history üí°</h3>  

<div align="center">

[![GitHub stars](https://img.shields.io/github/stars/xming521/WeClone?style=for-the-badge&logo=github&label=Stars&logoColor=white&color=ffda65)](https://github.com/xming521/WeClone/stargazers)
[![GitHub release](https://img.shields.io/github/v/release/xming521/WeClone?style=for-the-badge&logo=github&label=Release&logoColor=white&color=06d094)](https://github.com/xming521/WeClone/releases)
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white)](https://t.me/+JEdak4m0XEQ3NGNl)
[![Twitter](https://img.shields.io/badge/Twitter-@weclone567-000000?style=for-the-badge&logo=x&logoColor=white)](https://x.com/weclone567)
[![Â∞èÁ∫¢‰π¶](https://img.shields.io/badge/WeClone-FE2C55?style=for-the-badge&logo=xiaohongshu&logoColor=white)](https://www.xiaohongshu.com/user/profile/628109730000000021029de4)
<a href="https://qm.qq.com/cgi-bin/qm/qr?k=wNdgbOVT6oFOJ2wlMLsolUXErW9ESLpk&jump_from=webapi&authKey=z/reOp6YLyvR4Tl2k2nYMsLoMC3w9/99ucgKMX0oRGlxDV/WbYnvq2QxODoIkfxn" target="_blank" style="text-decoration: none;">
  <img src="https://img.shields.io/badge/QQÁæ§-708067078-12B7F5?style=for-the-badge&logo=qq&logoColor=white" alt="WeClone‚ë†" title="WeClone‚ë†">
</a>


<a href="https://hellogithub.com/repository/12ab209b56cb4cfd885c8cfd4cfdd53e" target="_blank"><img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=12ab209b56cb4cfd885c8cfd4cfdd53e&claim_uid=RThlPDoGrFvdMY5" alt="FeaturedÔΩúHelloGitHub" style="width: 150px; height: 28px;" /></a>
<a href="https://trendshift.io/repositories/13759" target="_blank"><img src="https://trendshift.io/api/badge/repositories/13759" alt="xming521%2FWeClone | Trendshift" style="width: 220px; height: 50px;" /></a>
<a href="https://deepwiki.com/xming521/WeClone"><img src="https://deepwiki.com/badge.svg" alt="Ask DeepWiki"  style="width: 134px; height: 23px;margin-bottom: 3px;"></a>
</div>

<p align="center">
  <a href="https://github.com/xming521/WeClone/blob/master/README_zh.md" target="_blank">ÁÆÄ‰Ωì‰∏≠Êñá</a>ÔΩú
  English</a>ÔΩú
  <a href="https://www.weclone.love/" target="_blank"> Project Homepage </a> ÔΩú
  <a href="https://docs.weclone.love/what-is-weclone.html" target="_blank"> Documentation </a> 
</p>

> [!IMPORTANT]
> ### WhatsApp and Telegram chat logs integration for digital avatar creation is coming !

## ‚ú®Core Features
- üí´ Complete end-to-end solution for creating digital avatars, including chat data export, preprocessing, model training, and deployment
- üí¨ Fine-tune LLM using chat history with support for image modal data, infusing it with that authentic "flavor"
- üîó Integrate with Telegram, WeChat, WhatsApp (coming soon) to create your own digital avatar
- üõ°Ô∏è Privacy information filtering with localized fine-tuning and deployment for secure and controllable data

## üìãFeatures & Notes
> [!IMPORTANT]
> ### WeClone is currently not partnered with any platform and has not issued any cryptocurrency. The only official website is: [weclone.love](https://www.weclone.love). Beware of imitations.

### Chat Platform Support

| Platform | Text | Images | Voice | Video | Animated Emojis | Links (Sharing) | Quote | Forward | Location | Files |
|----------|------|--------|-------|-------|-----------------|-----------------|-------|---------|----------|-------|
| WeChat | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| Telegram | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ö†Ô∏èConvert to Emoji | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ | ‚ùå |

 

> [!IMPORTANT]
> - WeClone is still in rapid iteration phase, current performance does not represent final results.  
> - LLM fine-tuning effectiveness largely depends on model size, quantity and quality of chat data. Theoretically, larger models with more data yield better results.
> - 7B models are prone to becoming "dumb", 14B models can barely communicate, while 32B+ models perform much better.   
> - Windows environment has not been rigorously tested. You can use WSL as the runtime environment.

### Recent Updates
[25/06/05] Support for image modal data fine-tuning

### Hardware Requirements

The project uses Qwen2.5-VL-7B-Instruct model by default with LoRA method for SFT stage fine-tuning. You can also use other models and methods supported by [LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory/tree/main#supported-models).

Estimated VRAM requirements (text-only large model memory usage as follows, vision models increase based on image quantity and size): 
| Method                          | Precision |   7B  |  14B  |  30B  |   70B  |   `x`B  |
| ------------------------------- | --------- | ----- | ----- | ----- | ------ | ------- |
| Full (`bf16` or `fp16`)         |    32     | 120GB | 240GB | 600GB | 1200GB | `18x`GB |
| Full (`pure_bf16`)              |    16     |  60GB | 120GB | 300GB |  600GB |  `8x`GB |
| Freeze/LoRA/GaLore/APOLLO/BAdam |    16     |  16GB |  32GB |  64GB |  160GB |  `2x`GB |
| QLoRA                           |     8     |  10GB |  20GB |  40GB |   80GB |   `x`GB |
| QLoRA                           |     4     |   6GB |  12GB |  24GB |   48GB | `x/2`GB |
| QLoRA                           |     2     |   4GB |   8GB |  16GB |   24GB | `x/4`GB |


## Environment Setup
1. CUDA installation (skip if already installed, **requires version 12.6 or above**)

2. It is recommended to use [uv](https://docs.astral.sh/uv/) to install dependencies, which is a very fast Python environment manager. After installing uv, you can use the following commands to create a new Python environment and install dependencies. 
```bash
git clone https://github.com/xming521/WeClone.git && cd WeClone
uv venv .venv --python=3.10
source .venv/bin/activate # windows .venv\Scripts\activate
uv pip install --group main -e . 
```

3. Copy the configuration file template and rename it to `settings.jsonc`, and make subsequent configuration changes in this file:

```bash
cp examples/tg.template.jsonc settings.jsonc
```

> [!NOTE]
> Training and inference related configurations are unified in the file `settings.jsonc`

4. Use the following command to test whether the CUDA environment is correctly configured and can be recognized by PyTorch (not needed for Mac):
```bash
  python -c "import torch; print('CUDA Available:', torch.cuda.is_available());"
```

5. (Optional) Install FlashAttention to accelerate training and inference: `uv pip install flash-attn --no-build-isolation`.

## Model Download
It is recommended to use [Hugging Face](https://huggingface.co/docs/hub/models-downloading) to download models, or use the following command:
```bash
git lfs install
git clone https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct models/Qwen2.5-VL-7B-Instruct
```

## Data Preparation

Please use [Telegram Desktop](https://desktop.telegram.org/) to export chat records. Select Photos for message types and JSON for format. You can export multiple contacts (group chat records are not recommended), then place the exported `ChatExport_*` in the `./dataset/telegram` directory, meaning put different people's chat record folders together in `./dataset/telegram`.   


## Data Preprocessing

- By default, the project uses Microsoft Presidio to remove `phone numbers, email addresses, credit card numbers, IP addresses, geographic location names, international bank account numbers, cryptocurrency wallet addresses, age information, and generic ID numbers` from the data, but it cannot guarantee 100% identification.
- Therefore, a blocklist `blocked_words` is provided in `settings.jsonc`, allowing users to manually add words or phrases they want to filter (the entire sentence containing blocked words will be removed by default).

> [!IMPORTANT]
> üö® Please be sure to protect personal privacy and do not leak personal information!

- Execute the following command to process the data. You can modify the `make_dataset_args` in settings.jsonc according to your own chat style.
```bash
weclone-cli make-dataset
```
- Currently supports time window strategy. Messages from a single person are combined into one sentence by commas based on `single_combine_time_window`, and Q&A pairs are matched based on `qa_match_time_window`.
- For **training multimodal large models**: Enable by adding `images` to `include_type`, and control image quantity and size through `image_max_pixels` and `max_image_num` parameters to reduce VRAM usage.
- For **Image to Text**: Add `images` to `include_type` and configure `vision_api` parameters. The system will use external multimodal models to convert images to text, and the final generated dataset **is still used for training text-only LLM**.
- You can enable the `enable_clean` option in `clean_dataset` to clean the data for better results (multimodal data is not currently supported). The current system supports using `llm judge` to score chat records, providing **vllm offline inference** and **API online inference** methods. By default, offline inference is enabled. To switch to API-based online inference mode, modify `"online_llm_clear": false` to `true` in the `settings.jsonc` file, and configure relevant parameters such as `base_url`, `llm_api_key`, and `model_name`. All models compatible with OpenAI interface can be accessed.
- After obtaining the `llm scoring score distribution`, you can filter acceptable data by setting the `accept_score` parameter, and appropriately reduce the `lora_dropout` parameter in `train_sft_args` to improve the model's fitting effect.

## Configure Parameters and Fine-tune Model

- (Optional) Modify `model_name_or_path`, `template`, `lora_target` in `settings.jsonc` to select other locally downloaded models.   
- Modify `per_device_train_batch_size` and `gradient_accumulation_steps` to adjust VRAM usage.  
- You can modify parameters like `num_train_epochs`, `lora_rank`, `lora_dropout` in `train_sft_args` based on your dataset's quantity and quality.

### Single GPU Training
```bash
weclone-cli train-sft
```

### Multi-GPU Training
Uncomment the `deepspeed` line in `settings.jsonc` and use the following command for multi-GPU training:
```bash
uv pip install deepspeed
deepspeed --num_gpus=number_of_gpus weclone/train/train_sft.py
```

### ‰ΩøÁî®ÊµèËßàÂô®demoÁÆÄÂçïÊé®ÁêÜ
ÂèØ‰ª•Âú®Ëøô‰∏ÄÊ≠•ÊµãËØïÂá∫ÂêàÈÄÇÁöÑtemperature„ÄÅtop_pÂÄºÔºå‰øÆÊîπsettings.jsoncÁöÑ`infer_args`ÂêéÔºå‰æõÂêéÁª≠Êé®ÁêÜÊó∂‰ΩøÁî®„ÄÇ
```bash
weclone-cli webchat-demo
```

### ‰ΩøÁî®Êé•Âè£ËøõË°åÊé®ÁêÜ

```bash
weclone-cli server
```

### ‰ΩøÁî®Â∏∏ËßÅËÅäÂ§©ÈóÆÈ¢òÊµãËØï
‰∏çÂåÖÂê´ËØ¢ÈóÆ‰∏™‰∫∫‰ø°ÊÅØÁöÑÈóÆÈ¢òÔºå‰ªÖÊúâÊó•Â∏∏ËÅäÂ§©„ÄÇÊµãËØïÁªìÊûúÂú®test_result-my.txt„ÄÇ
```bash
weclone-cli server
weclone-cli test-model
```

## üñºÔ∏è ÂæÆË∞ÉÊïàÊûú
> [!TIP] 
> **QQÁæ§ÂÜÖÊúâÈÉ®ÁΩ≤Â•ΩÁöÑQwen2.5VL 32B BotÔºåÂèØ‰ª•‰ΩìÈ™åÊïàÊûú„ÄÇÊõ¥Â§öÊ°à‰æãÂèØ‰ª•ÂÖ≥Ê≥®[Â∞èÁ∫¢‰π¶](https://www.xiaohongshu.com/user/profile/628109730000000021029de4)**  

‰ΩøÁî®Qwen2.5-14B-InstructÊ®°ÂûãÔºåÂ§ßÊ¶Ç3‰∏áÊù°Â§ÑÁêÜÂêéÁöÑÊúâÊïàÊï∞ÊçÆÔºålossÈôçÂà∞‰∫Ü3.5Â∑¶Âè≥ÁöÑÊïàÊûúÔºö
<details>
<summary>Êà™Âõæ</summary>
<div style="display: flex; flex-wrap: wrap; gap: 10px;">
  <img src="https://github.com/user-attachments/assets/0775ec52-452b-485f-9785-c6eb7b277132" alt="alt text" style="width: 48%; min-width: 150px;">
  <img src="https://github.com/user-attachments/assets/8c7628b5-da70-4c37-9e51-fdfb0eadd2df" alt="alt text" style="width: 48%; min-width: 150px;">
  <img src="https://github.com/user-attachments/assets/523aa742-2aa3-40e9-bd67-b98b336e83a8" alt="alt text" style="width: 48%; min-width: 150px;">
  <img src="https://github.com/user-attachments/assets/dabf0603-dcc4-4a47-b5c3-2bbc036820d9" alt="alt text" style="width: 48%; min-width: 150px;">
</div>
</details>


## ü§ñ ÈÉ®ÁΩ≤Âà∞ËÅäÂ§©Êú∫Âô®‰∫∫
### LangBot

[LangBot](https://github.com/RockChinQ/LangBot) ÊòØ‰∏Ä‰∏™ÂºÄÊ∫êÁöÑÊé•ÂÖ•ÂÖ®ÁêÉÂ§öÁßçÂç≥Êó∂ÈÄö‰ø°Âπ≥Âè∞ÁöÑ LLM Êú∫Âô®‰∫∫Âπ≥Âè∞ÔºåÊîØÊåÅDiscord„ÄÅTelegram„ÄÅSlackÁ≠âÂπ≥Âè∞ÔºåÈÄÇÂêàÂêÑÁßçÂú∫ÊôØ‰ΩøÁî®„ÄÇ

1. [ÈÉ®ÁΩ≤ LangBot](https://github.com/RockChinQ/LangBot/blob/master/README_EN.md#-getting-started)
2. Âú® LangBot ‰∏≠Ê∑ªÂä†‰∏Ä‰∏™Êú∫Âô®‰∫∫
4. Âú®Ê®°ÂûãÈ°µÊ∑ªÂä†Êñ∞Ê®°ÂûãÔºåÂêçÁß∞`gpt-3.5-turbo`Ôºå‰æõÂ∫îÂïÜÈÄâÊã© OpenAIÔºåÂ°´ÂÜô ËØ∑Ê±Ç URL ‰∏∫ WeClone ÁöÑÂú∞ÂùÄÔºåËØ¶ÁªÜËøûÊé•ÊñπÂºèÂèØ‰ª•ÂèÇËÄÉ[ÊñáÊ°£](https://docs.langbot.app/en/workshop/network-details.html)ÔºåAPI Key ‰ªªÊÑèÂ°´ÂÜô„ÄÇ

<img width="400px" alt="image" src="https://github.com/user-attachments/assets/fc167dea-7c93-4d94-9c5f-db709d0320ba" />

6. Âú®ÊµÅÊ∞¥Á∫øÈÖçÁΩÆ‰∏≠ÈÄâÊã©ÂàöÊâçÊ∑ªÂä†ÁöÑÊ®°ÂûãÔºåÊàñ‰øÆÊîπÊèêÁ§∫ËØçÈÖçÁΩÆ

<img width="400px" alt="image" src="https://github.com/user-attachments/assets/dbb0fd0a-f760-42db-acd0-bb99c859b52e" />

### AstrBot

[AstrBot](https://github.com/AstrBotDevs/AstrBot) ÊòØÊòì‰∏äÊâãÁöÑÂ§öÂπ≥Âè∞ LLM ËÅäÂ§©Êú∫Âô®‰∫∫ÂèäÂºÄÂèëÊ°ÜÊû∂ ‚ú® Âπ≥Âè∞ÊîØÊåÅ QQ„ÄÅTelegram„ÄÅÂæÆ‰ø°„ÄÅ‰ºÅÂæÆ„ÄÅÈ£û‰π¶„ÄÇ      

‰ΩøÁî®Ê≠•È™§Ôºö
1. ÈÉ®ÁΩ≤ AstrBot
2. Âú® AstrBot ‰∏≠ÈÉ®ÁΩ≤Ê∂àÊÅØÂπ≥Âè∞
3. ÊâßË°å `weclone-cli server` ÂêØÂä®apiÊúçÂä°
4. Âú® AstrBot ‰∏≠Êñ∞Â¢ûÊúçÂä°Êèê‰æõÂïÜÔºåÁ±ªÂûãÈÄâÊã©OpenAIÔºåAPI Base URL Ê†πÊçÆAstrBotÈÉ®ÁΩ≤ÊñπÂºèÂ°´ÂÜôÔºà‰æãÂ¶ÇdockerÈÉ®ÁΩ≤ÂèØËÉΩ‰∏∫http://172.17.0.1:8005/v1Ôºâ ÔºåÊ®°ÂûãÂ°´ÂÜôgpt-3.5-turbo,API KeyÈöèÊÑèÂ°´ÂÜô‰∏Ä‰∏™
5. ÂæÆË∞ÉÂêé‰∏çÊîØÊåÅÂ∑•ÂÖ∑Ë∞ÉÁî®ÔºåËØ∑ÂÖàÂÖ≥ÊéâÈªòËÆ§ÁöÑÂ∑•ÂÖ∑ÔºåÊ∂àÊÅØÂπ≥Âè∞ÂèëÈÄÅÊåá‰ª§Ôºö `/tool off all`ÔºåÂê¶Âàô‰ºöÊ≤°ÊúâÂæÆË∞ÉÂêéÁöÑÊïàÊûú„ÄÇ 
6. Ê†πÊçÆÂæÆË∞ÉÊó∂‰ΩøÁî®ÁöÑdefault_systemÔºåÂú® AstrBot ‰∏≠ËÆæÁΩÆÁ≥ªÁªüÊèêÁ§∫ËØç„ÄÇ
![5](https://github.com/user-attachments/assets/19de7072-076a-4cdf-8ae6-46b9b89f536a)
> [!IMPORTANT]
> Ê£ÄÊü•api_serviceÁöÑÊó•ÂøóÔºåÂ∞ΩÈáè‰øùËØÅÂ§ßÊ®°ÂûãÊúçÂä°ËØ∑Ê±ÇÁöÑÂèÇÊï∞ÂíåÂæÆË∞ÉÊó∂‰∏ÄËá¥ÔºåtoolÊèí‰ª∂ËÉΩÂäõÈÉΩÂÖ≥Êéâ„ÄÇ
7. Ë∞ÉÊï¥ÈááÊ†∑ÂèÇÊï∞Ôºå‰æãÂ¶Çtemperature„ÄÅtop_p„ÄÅtop_kÁ≠â
[ÈÖçÁΩÆËá™ÂÆö‰πâÁöÑÊ®°ÂûãÂèÇÊï∞](https://astrbot.app/config/model-config.html#%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0)


## üìå Ë∑ØÁ∫øÂõæ
- [ ] ÊîØÊåÅÊõ¥Â§öÊï∞ÊçÆÊ∫ê
- [ ] Êõ¥‰∏∞ÂØåÁöÑ‰∏ä‰∏ãÊñáÔºöÂåÖÊã¨‰∏ä‰∏ãÊñáÂØπËØù„ÄÅËÅäÂ§©ÂØπË±°‰ø°ÊÅØ„ÄÅÊó∂Èó¥Á≠â 
- [ ] Memory ÊîØÊåÅ
- [ ] ÊîØÊåÅÂ§öÊ®°ÊÄÅ:Â∑≤ÊîØÊåÅÂõæÁâá
- [ ] Êï∞ÊçÆÂ¢ûÂº∫
- [ ] ÊîØÊåÅGUI
- [ ] ÊîØÊåÅCOTÊÄùËÄÉ

## ÈóÆÈ¢òËß£ÂÜ≥
#### [ÂÆòÊñπÊñáÊ°£FAQ](https://www.weclone.love/FAQ.html)    
ÂêåÊó∂Âª∫ËÆÆ‰ΩøÁî®[DeepWiki](https://deepwiki.com/xming521/WeClone)Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÇ



## ‚ù§Ô∏è Ë¥°ÁåÆ‰ª£Á†Å

Ê¨¢Ëøé‰ªª‰Ωï Issues/Pull RequestsÔºÅ

‰Ω†ÂèØ‰ª•ÈÄöËøáÊü•ÁúãIssuesÊàñÂ∏ÆÂä©ÂÆ°Ê†∏ PRÔºàÊãâÂèñËØ∑Ê±ÇÔºâÊù•Ë¥°ÁåÆ„ÄÇÂØπ‰∫éÊñ∞ÂäüËÉΩÁöÑÊ∑ªÂä†ÔºåËØ∑ÂÖàÈÄöËøá Issue ËÆ®ËÆ∫„ÄÇ   
ÂºÄÂèëÁéØÂ¢ÉÔºö
```bash
uv pip install --group dev -e .
pre-commit install
```

È°πÁõÆ‰ΩøÁî®`pytest`ÊµãËØïÔºå`pyright`Ê£ÄÊü•Á±ªÂûãÔºå`ruff`Ê£ÄÊü•‰ª£Á†ÅÊ†ºÂºè„ÄÇ

## üôè Ëá¥Ë∞¢

ÊÑüË∞¢‰ª•‰∏ã‰ª£Á†ÅË¥°ÁåÆËÄÖÂíåÁ§æÂå∫ÈáåÂÖ∂‰ªñÊàêÂëòÁöÑË¥°ÁåÆ

<a href="https://github.com/xming521/WeClone/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=xming521/WeClone" />
</a>

ÂêåÊó∂Êú¨È°πÁõÆÂèóÁõä‰∫é[PyWxDump](https://github.com/xaoyaoo/PyWxDump)„ÄÅ[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)„ÄÅ[AstrBot](https://github.com/AstrBotDevs/AstrBot)„ÄÅ[LangBot](https://github.com/RockChinQ/LangBot)Á≠â‰ºòÁßÄÂºÄÊ∫êÈ°πÁõÆ„ÄÇ

## ‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé
> [!CAUTION]
> **Êú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†„ÄÅÁ†îÁ©∂ÂíåÂÆûÈ™åÁî®ÈÄîÔºåÁî®‰∫éÁîü‰∫ßÁéØÂ¢ÉÂ≠òÂú®ËæÉÂ§ßÈ£éÈô©ÔºåËØ∑Ë∞®ÊÖéËØÑ‰º∞„ÄÇËØ∑ÂãøÁî®‰∫éÈùûÊ≥ïÁî®ÈÄîÔºåÂêéÊûúËá™Ë¥ü„ÄÇ**
<details>
<summary>ÁÇπÂáªÊü•ÁúãÂÖçË¥£Êù°Ê¨æ</summary>

### 1. ‰ΩøÁî®È£éÈô©Ëá™ÊãÖ
- Áî®Êà∑Âú®‰ΩøÁî®Êú¨È°πÁõÆÊó∂ÔºåÂ∫îÂÖÖÂàÜÁêÜËß£Âπ∂ÊâøÊãÖÊâÄÊúâÁõ∏ÂÖ≥È£éÈô©
- **Êú¨È°πÁõÆ‰ΩúËÄÖ‰∏çÂØπÂõ†‰ΩøÁî®Êú¨È°πÁõÆËÄå‰∫ßÁîüÁöÑ‰ªª‰ΩïÁõ¥Êé•ÊàñÈó¥Êé•ÊçüÂ§±ÊâøÊãÖË¥£‰ªª**
- ÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÔºöÊï∞ÊçÆ‰∏¢Â§±„ÄÅÁªèÊµéÊçüÂ§±„ÄÅÊ≥ïÂæãÁ∫†Á∫∑„ÄÅ‰∏™‰∫∫ÂêçË™âÊçüÂÆ≥„ÄÅÁ§æ‰ºöÂÖ≥Á≥ªÂΩ±Âìç„ÄÅÂøÉÁêÜÂàõ‰º§„ÄÅËÅå‰∏öÂèëÂ±ïÂèóÈòª„ÄÅÂïÜ‰∏ö‰ø°Ë™âÂèóÊçüÁ≠â

### 2. Áîü‰∫ßÁéØÂ¢ÉÈ£éÈô©Ë≠¶Âëä
- **Áî®‰∫éÂïÜ‰∏öÁî®ÈÄîÊàñÂØπÂ§ñÊèê‰æõÊúçÂä°ÈúÄËá™Ë°åÊâøÊãÖÂÖ®ÈÉ®È£éÈô©**
- Áîü‰∫ßÁéØÂ¢É‰ΩøÁî®ÂèØËÉΩÂØºËá¥ÁöÑÊâÄÊúâÂêéÊûúÔºàÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÊúçÂä°‰∏≠Êñ≠„ÄÅÊï∞ÊçÆÂÆâÂÖ®ÈóÆÈ¢ò„ÄÅÁî®Êà∑ÊäïËØâ„ÄÅÊ≥ïÂæãË¥£‰ªªÁ≠âÔºâÂÆåÂÖ®Áî±Áî®Êà∑ÊâøÊãÖ
- **Âª∫ËÆÆÂú®Áîü‰∫ßÁéØÂ¢É‰ΩøÁî®ÂâçËøõË°åÂÖÖÂàÜÁöÑÊµãËØï„ÄÅÈ™åËØÅÂíåÈ£éÈô©ËØÑ‰º∞**

### 3. Ê®°ÂûãËæìÂá∫‰∏çÂèØÈù†ÊÄß
- ÂæÆË∞ÉÂêéÁöÑÊ®°ÂûãÂèØËÉΩ‰∫ßÁîü‰∏çÂáÜÁ°Æ„ÄÅÊúâÂÆ≥ÊàñËØØÂØºÊÄßÁöÑÂÜÖÂÆπ
- Ê®°ÂûãËæìÂá∫‰∏ç‰ª£Ë°®ÁúüÂÆû‰∫∫Áâ©ÁöÑËßÇÁÇπÊàñÊÑèÂõæ
- Áî®Êà∑Â∫îÂØπÊ®°ÂûãËæìÂá∫ËøõË°å‰∫∫Â∑•ÂÆ°Ê†∏ÂíåÈ™åËØÅ

### 4. Êï∞ÊçÆÂÆâÂÖ®‰∏éÈöêÁßÅ
- Áî®Êà∑Â∫îÁ°Æ‰øù‰∏ä‰º†ÁöÑËÅäÂ§©ËÆ∞ÂΩïÁ≠âÊï∞ÊçÆÁ¨¶ÂêàÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑ
- Áî®Êà∑Â∫îËé∑Âæó**Êï∞ÊçÆÁõ∏ÂÖ≥‰∫∫ÂëòÁöÑÈÄÇÂΩìÊéàÊùÉ**
- Êú¨È°πÁõÆ‰∏çÂØπ**Êï∞ÊçÆÊ≥ÑÈú≤ÊàñÈöêÁßÅ‰æµÁäØ**ÊâøÊãÖË¥£‰ªª

### 5. Ê≥ïÂæãÂêàËßÑ
- **Áî®Êà∑Â∫îÁ°Æ‰øù‰ΩøÁî®Êú¨È°πÁõÆÁ¨¶ÂêàÂΩìÂú∞Ê≥ïÂæãÊ≥ïËßÑ**
- Ê∂âÂèä‰∫∫Â∑•Êô∫ËÉΩ„ÄÅÊï∞ÊçÆ‰øùÊä§„ÄÅÁü•ËØÜ‰∫ßÊùÉÁ≠âÁõ∏ÂÖ≥Ê≥ïÂæã
- **ËøùÊ≥ï‰ΩøÁî®ÈÄ†ÊàêÁöÑÂêéÊûúÁî±Áî®Êà∑ÊâøÊãÖ**

### 6. ÊäÄÊúØÊîØÊåÅÈôêÂà∂
- Êú¨È°πÁõÆÊåâ"Áé∞Áä∂"Êèê‰æõÔºå‰∏çÊèê‰æõ‰ªª‰ΩïÊòéÁ§∫ÊàñÊöóÁ§∫ÁöÑ‰øùËØÅ
- ‰ΩúËÄÖ‰∏çÊâøËØ∫Êèê‰æõÊåÅÁª≠ÁöÑÊäÄÊúØÊîØÊåÅÊàñÁª¥Êä§
- ‰∏ç‰øùËØÅÈ°πÁõÆÁöÑÁ®≥ÂÆöÊÄß„ÄÅÂèØÈù†ÊÄßÊàñÈÄÇÁî®ÊÄß

## ‰ΩøÁî®Âª∫ËÆÆ

### Âº∫Âà∂ÊÄßBotË∫´‰ªΩÊ†áËØÜ
**‰ΩøÁî®Êú¨È°πÁõÆÁîüÊàêÁöÑÊï∞Â≠óÂàÜË∫´Êó∂ÔºåÂº∫ÁÉàÂª∫ËÆÆÔºö**
- Âú®ÊØèÊ¨°ÂØπËØùÂºÄÂßãÊó∂ÊòéÁ°ÆÊ†áËØÜ‰∏∫"AI Bot"Êàñ"Êï∞Â≠óÂàÜË∫´"
- Âú®Áî®Êà∑ÁïåÈù¢ÊòæËëó‰ΩçÁΩÆÊ†áÊ≥®"Ê≠§‰∏∫AIÁîüÊàêÂÜÖÂÆπ"
- ÈÅøÂÖçËÆ©Áî®Êà∑ËØØËÆ§‰∏∫ÊòØÁúüÂÆû‰∫∫Á±ªÂú®ÂØπËØùÔºå‰ªéËÄåÈÄ†ÊàêÈ£éÈô©

### È£éÈô©ËØÑ‰º∞Âª∫ËÆÆ

Â¶ÇÁ°ÆÈúÄÂú®Áîü‰∫ßÁéØÂ¢É‰ΩøÁî®ÔºåÂª∫ËÆÆÔºö
1. ËøõË°åÂÖ®Èù¢ÁöÑÂÆâÂÖ®ÊÄßÊµãËØï
2. Âª∫Á´ãÂÆåÂñÑÁöÑÂÜÖÂÆπÂÆ°Ê†∏Êú∫Âà∂
3. Âà∂ÂÆöÂ∫îÊÄ•ÂìçÂ∫îÈ¢ÑÊ°à
4. Ë¥≠‰π∞Áõ∏Â∫îÁöÑ‰øùÈô©‰øùÈöú
5. Âí®ËØ¢Ê≥ïÂæã‰∏ì‰∏ö‰∫∫Â£´ÊÑèËßÅ


Êú¨ÂÖçË¥£Â£∞ÊòéÂèØËÉΩÈöèÈ°πÁõÆÊõ¥Êñ∞ËÄå‰øÆËÆ¢ÔºåÁî®Êà∑Â∫îÂÆöÊúüÊü•ÁúãÊúÄÊñ∞ÁâàÊú¨„ÄÇÁªßÁª≠‰ΩøÁî®Êú¨È°πÁõÆÂç≥Ë°®Á§∫ÂêåÊÑèÊúÄÊñ∞ÁöÑÂÖçË¥£Â£∞ÊòéÊù°Ê¨æ„ÄÇ

**‰∏ÄÊó¶ÊÇ®‰∏ãËΩΩ„ÄÅÂÖãÈöÜ„ÄÅ‰øÆÊîπ„ÄÅÂàÜÂèëÊàñ‰ª•‰ªª‰ΩïÊñπÂºè‰ΩøÁî®Êú¨È°πÁõÆÁöÑ‰ª£Á†ÅÊàñÊ®°ÂûãÔºåÂç≥Ë°®Á§∫ÊÇ®Â∑≤ÂÆåÊï¥ÈòÖËØª„ÄÅÁêÜËß£Âπ∂ÂêåÊÑèÊó†Êù°‰ª∂Êé•ÂèóÊú¨ÂÖçË¥£Â£∞ÊòéÁöÑÂÖ®ÈÉ®Êù°Ê¨æ„ÄÇ**

</details>
**ËØ∑Áî®Êà∑ÊÖéÈáçÈòÖËØªÂπ∂ÁêÜËß£Êú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊâÄÊúâÂÜÖÂÆπÔºåÁ°Æ‰øùÂú®‰ΩøÁî®Êú¨È°πÁõÆÊó∂‰∏•Ê†ºÈÅµÂÆàÁõ∏ÂÖ≥ËßÑÂÆö„ÄÇ**

<br>  
<br>  
<br>  

## ‚≠ê Star History
> [!TIP] 
> Â¶ÇÊûúÊú¨È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåÊàñËÄÖÊÇ®ÂÖ≥Ê≥®Êú¨È°πÁõÆÁöÑÊú™Êù•ÂèëÂ±ïÔºåËØ∑ÁªôÈ°πÁõÆ StarÔºåË∞¢Ë∞¢ 

<div align="center">

[![Star History Chart](https://api.star-history.com/svg?repos=xming521/WeClone&type=Date)](https://www.star-history.com/#xming521/WeClone&Date)

</div>


<div align="center"> ÂÖãÈöÜÊàë‰ª¨Ôºå‰øùÁïôÁÅµÈ≠ÇÁöÑËä¨Ëä≥ </div>
